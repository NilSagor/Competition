{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "data = pd.read_csv('Data/train.csv')\n",
    "data.head()\n",
    "\n",
    "test_data = pd.read_csv('Data/test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['gender'] = np.where(data['gender']==\"Male\",1,0)\n",
    "data['ever_married'] = np.where(data['ever_married']==\"Yes\",1,0)\n",
    "data['Residence_type'] = np.where(data['Residence_type']==\"Rural\",1,0)\n",
    "data['smoking_status'].fillna(0,inplace=True)\n",
    "data['smoking_status'] = np.where(data['smoking_status']==\"formerly smoked\",3,data['smoking_status'])\n",
    "data['smoking_status'] = np.where(data['smoking_status']==\"never smoked\",1,data['smoking_status'])\n",
    "data['smoking_status'] = np.where(data['smoking_status']==\"smokes\",2,data['smoking_status'])\n",
    "bmi_mean = data['bmi'].mean()\n",
    "data['bmi'].fillna(bmi_mean,inplace=True)\n",
    "data = pd.get_dummies(data,columns = ['work_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['gender'] = np.where(test_data['gender']==\"Male\",1,0)\n",
    "test_data['ever_married'] = np.where(test_data['ever_married']==\"Yes\",1,0)\n",
    "test_data['Residence_type'] = np.where(test_data['Residence_type']==\"Rural\",1,0)\n",
    "test_data['smoking_status'].fillna(0,inplace=True)\n",
    "test_data['smoking_status'] = np.where(test_data['smoking_status']==\"formerly smoked\",3,test_data['smoking_status'])\n",
    "test_data['smoking_status'] = np.where(test_data['smoking_status']==\"never smoked\",1,test_data['smoking_status'])\n",
    "test_data['smoking_status'] = np.where(test_data['smoking_status']==\"smokes\",2,test_data['smoking_status'])\n",
    "test_data['bmi'].fillna(bmi_mean,inplace=True)\n",
    "test_data = pd.get_dummies(test_data,columns = ['work_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "df_majority = data[data.stroke==0]\n",
    "df_minority = data[data.stroke==1]\n",
    " \n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=int(len(df_majority)/3),    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "data = pd.concat([df_majority, df_minority_upsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = data['stroke']\n",
    "data.drop(['stroke'], axis = 1, inplace = True)\n",
    "train_x = data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shubham.gupta\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBC  N&Depth:  70_2  Value:  0.847\n",
      "GBC  N&Depth:  70_3  Value:  0.844\n",
      "GBC  N&Depth:  70_4  Value:  0.838\n",
      "GBC  N&Depth:  75_2  Value:  0.847\n",
      "GBC  N&Depth:  75_3  Value:  0.845\n",
      "GBC  N&Depth:  75_4  Value:  0.837\n",
      "GBC  N&Depth:  80_2  Value:  0.847\n",
      "GBC  N&Depth:  80_3  Value:  0.844\n",
      "GBC  N&Depth:  80_4  Value:  0.837\n",
      "GBC  N&Depth:  85_2  Value:  0.847\n",
      "GBC  N&Depth:  85_3  Value:  0.845\n",
      "GBC  N&Depth:  85_4  Value:  0.837\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "n_estimator = 40\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.ensemble import (RandomTreesEmbedding, RandomForestClassifier,\n",
    "                              GradientBoostingClassifier)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_x, train_y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "X_train['stroke'] = y_train\n",
    "\n",
    "df_majority = X_train[X_train.stroke==0]\n",
    "df_minority = X_train[X_train.stroke==1]\n",
    " \n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=int(len(df_majority)/3),    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "X_train = pd.concat([df_majority, df_minority_upsampled])\n",
    "\n",
    "y_train = X_train['stroke']\n",
    "X_train.drop(['stroke'], axis = 1, inplace = True)\n",
    "\n",
    "depth = [2,3,4]\n",
    "leaf = [1]\n",
    "for i in range(4):\n",
    "    for j in depth:\n",
    "        n_estimator = 70 + i*5\n",
    "        grd = GradientBoostingClassifier(n_estimators=n_estimator,max_depth=j)\n",
    "        grd.fit(X_train, y_train)\n",
    "        y_pred_grd = grd.predict_proba(X_test)[:, 1]\n",
    "        fpr_grd, tpr_grd, _ = roc_curve(y_test, y_pred_grd)\n",
    "        key = str(n_estimator) + \"_\" + str(j)\n",
    "        print (\"GBC \", \"N&Depth: \",key,\" Value: \",round(auc(fpr_grd, tpr_grd),3))\n",
    "print (\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "test_id = test_data['id']\n",
    "\n",
    "train_x['stroke'] = train_y\n",
    "\n",
    "df_majority = train_x[train_x.stroke==0]\n",
    "df_minority = train_x[train_x.stroke==1]\n",
    " \n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=int(len(df_majority)/40),    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "train_x = pd.concat([df_majority, df_minority_upsampled])\n",
    "\n",
    "train_y = train_x['stroke']\n",
    "train_x.drop(['stroke'], axis = 1, inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "grd = GradientBoostingClassifier(n_estimators=65, max_depth=2)\n",
    "grd.fit(train_x, train_y)\n",
    "y_pred_grd = grd.predict_proba(test_data)[:,1]\n",
    "y_pred_grd1 = grd.predict(test_data)\n",
    "print (round(100*np.mean(y_pred_grd1)))\n",
    "print (sum(y_pred_grd1))\n",
    "#pr_grd, tpr_grd, _ = roc_curve(y_test, y_pred_grd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.16711342, 0.18891896, 0.00356275, ..., 0.20090546, 0.02335519,\n",
       "       0.01073629])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_grd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('Submission/model12.csv',\"w\",newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    ps = ['id','stroke']\n",
    "    writer.writerow(ps)\n",
    "    for x,vc  in  zip(test_id,y_pred_grd):\n",
    "            writer.writerow([x,vc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8680"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred_grd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_x, train_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC 0.8159951558773629\n",
      "RFC+LR 0.7279843594041525\n",
      "GBC+LR 0.7260095992954002\n",
      "GBC 0.8128363417104185\n"
     ]
    }
   ],
   "source": [
    "n_estimator = 40\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.ensemble import (RandomTreesEmbedding, RandomForestClassifier,\n",
    "                              GradientBoostingClassifier)\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=2, min_samples_leaf=0.05, n_estimators =n_estimator, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "#y_pred = clf.predict(valid)\n",
    "y_pred_rf = clf.predict_proba(X_test)[:, 1]\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_pred_rf)\n",
    "print (\"RFC\", auc(fpr_rf, tpr_rf))\n",
    "\n",
    "X_train, X_train_lr, y_train, y_train_lr = train_test_split(X_train,\n",
    "                                                            y_train,\n",
    "                                                            test_size=0.2,random_state=42)\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(max_depth=3, min_samples_leaf=0.05,  n_estimators=n_estimator)\n",
    "rf_enc = OneHotEncoder()\n",
    "rf_lm = LogisticRegression()\n",
    "rf.fit(X_train, y_train)\n",
    "rf_enc.fit(rf.apply(X_train))\n",
    "rf_lm.fit(rf_enc.transform(rf.apply(X_train_lr)), y_train_lr)\n",
    "\n",
    "y_pred_rf_lm = rf_lm.predict_proba(rf_enc.transform(rf.apply(X_test)))[:, 1]\n",
    "fpr_rf_lm, tpr_rf_lm, _ = roc_curve(y_test, y_pred_rf_lm)\n",
    "print (\"RFC+LR\", auc(fpr_rf_lm, tpr_rf_lm))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "grd = GradientBoostingClassifier(n_estimators=n_estimator)\n",
    "grd_enc = OneHotEncoder()\n",
    "grd_lm = LogisticRegression()\n",
    "grd.fit(X_train, y_train)\n",
    "grd_enc.fit(grd.apply(X_train)[:, :, 0])\n",
    "grd_lm.fit(grd_enc.transform(grd.apply(X_train_lr)[:, :, 0]), y_train_lr)\n",
    "\n",
    "y_pred_grd_lm = grd_lm.predict_proba(\n",
    "    grd_enc.transform(grd.apply(X_test)[:, :, 0]))[:, 1]\n",
    "fpr_grd_lm, tpr_grd_lm, _ = roc_curve(y_test, y_pred_grd_lm)\n",
    "print (\"GBC+LR\", auc(fpr_grd_lm, tpr_grd_lm))\n",
    "\n",
    "# The gradient boosted model by itself\n",
    "y_pred_grd = grd.predict_proba(X_test)[:, 1]\n",
    "fpr_grd, tpr_grd, _ = roc_curve(y_test, y_pred_grd)\n",
    "print (\"GBC\", auc(fpr_grd, tpr_grd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBC 0.8128800875500068\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
